12:55:15] INFO     importing modules...done in 2.46 s                                                               train.py:16

           INFO                          program arguments                                                          utils.py:156
                     ─────────────────────────────────────────────────────────                                                  
                      method:          gap-ndp     encoder_epochs:   1                                                          
                      dataset:         reddit      epochs:           1                                                          
                      data_dir:        ./datasets  optimizer:        adam                                                       
                      delta:           auto        learning_rate:    0.01                                                       
                      max_degree:      100         weight_decay:     0.0                                                        
                      max_grad_norm:   1.0         full_batch_eval:  True                                                       
                      batch_size:      256         device:           cuda                                                       
                      hops:            2           val_interval:     1                                                          
                      hidden_dim:      16          seed:             12345                                                      
                      encoder_layers:  2           repeats:          1                                                          
                      base_layers:     1           debug:            False                                                      
                      head_layers:     1           logger:           csv                                                        
                      combine:         cat         project:          GAP                                                        
                      activation:      selu        output_dir:       ./output                                                   
                      dropout:         0.0         epsilon:          8.0                                                        
                     ─────────────────────────────────────────────────────────                                                  

[12:55:25] INFO                            dataset: reddit                                                          loader.py:76
                     ────────────────────────────────────────────────────────────                                               
                      nodes:     116,713     mean degree:         396.13                                                        
                      edges:     46,233,380  median degree:       209.0                                                         
                      features:  602         train/val/test (%):  75.0/10.0/15.0                                                
                      classes:   8           baseline acc (%):    24.35                                                         
                     ────────────────────────────────────────────────────────────                                               

           INFO     loading dataset...done in 10.77 s                                                                train.py:34
           INFO     delta = 1e-05                                                                                  gap_ndp.py:85
eps1 8.0
eps3 8.0
eps5 8.0
[12:55:27] INFO     noise scale: 0.9033                                                                            gap_ndp.py:90
                                                                                                                                
n 0.903304763649607
           INFO     calibrating noise to privacy budget...done in 1.16 s                                           gap_ndp.py:92
[12:55:28] INFO     pretraining encoder                                                                           gap_inf.py:121
1
341
epoch number:1 {'encoder/train/acc': 70.43331909179688, 'encoder/train/loss': 0.9292595982551575}
epoch number:1 {'encoder/val/acc': 74.5794677734375, 'encoder/val/loss': 0.8385176062583923}
                       overal progress   1/1 epochs ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:02                       
                       encoder/train/acc: 70.433 encoder/train/loss: 0.929  encoder/val/acc: 74.579 encoder/val/loss: 0.839     
                                                                                                                                
[12:55:41] INFO     bounding the number of neighbors per node...done in 10.05 s                                   gap_ndp.py:110
           INFO     computing aggregations...done in 0.00 s                                                       gap_inf.py:149
           INFO     training classifier                                                                               base.py:86
1
341
epoch number:1 {'train/acc': 85.81085205078125, 'train/loss': 0.5246462225914001}
epoch number:1 {'val/acc': 90.72261810302734, 'val/loss': 0.3170773386955261}
                       overal progress   1/1 epochs ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:02                       
                       train/acc: 85.811 train/loss: 0.525  val/acc: 90.723 val/loss: 0.317                                     
                                                                                                                                
[12:55:44] INFO                run 1                                                                                 train.py:66
                     ──────────────────────────                                                                                 
                      metric     last    mean                                                                                   
                     ──────────────────────────                                                                                 
                      test/acc   90.76   90.76                                                                                  
                     ──────────────────────────                                                                                 


           INFO     Total running time: 29.02 seconds.                                                              train.py:117
           INFO     Max GPU memory used = 1.74 GB                                                                   train.py:126
                                                                                                                                
[12:55:47] INFO     importing modules...done in 2.42 s                                                               train.py:16

           INFO                          program arguments                                                          utils.py:156
                     ─────────────────────────────────────────────────────────                                                  
                      method:          gap-ndp     encoder_epochs:   2                                                          
                      dataset:         reddit      epochs:           2                                                          
                      data_dir:        ./datasets  optimizer:        adam                                                       
                      delta:           auto        learning_rate:    0.01                                                       
                      max_degree:      100         weight_decay:     0.0                                                        
                      max_grad_norm:   1.0         full_batch_eval:  True                                                       
                      batch_size:      256         device:           cuda                                                       
                      hops:            2           val_interval:     1                                                          
                      hidden_dim:      16          seed:             12345                                                      
                      encoder_layers:  2           repeats:          1                                                          
                      base_layers:     1           debug:            False                                                      
                      head_layers:     1           logger:           csv                                                        
                      combine:         cat         project:          GAP                                                        
                      activation:      selu        output_dir:       ./output                                                   
                      dropout:         0.0         epsilon:          8.0                                                        
                     ─────────────────────────────────────────────────────────                                                  

[12:55:58] INFO                            dataset: reddit                                                          loader.py:76
                     ────────────────────────────────────────────────────────────                                               
                      nodes:     116,713     mean degree:         396.13                                                        
                      edges:     46,233,380  median degree:       209.0                                                         
                      features:  602         train/val/test (%):  75.0/10.0/15.0                                                
                      classes:   8           baseline acc (%):    24.35                                                         
                     ────────────────────────────────────────────────────────────                                               

           INFO     loading dataset...done in 10.69 s                                                                train.py:34
           INFO     delta = 1e-05                                                                                  gap_ndp.py:85
eps1 8.0
eps3 8.0
eps5 8.0
[12:55:59] INFO     noise scale: 0.9048                                                                            gap_ndp.py:90
                                                                                                                                
n 0.9048287351693665
           INFO     calibrating noise to privacy budget...done in 1.14 s                                           gap_ndp.py:92
[12:56:00] INFO     pretraining encoder                                                                           gap_inf.py:121
2
341
epoch number:1 {'encoder/train/acc': 70.42121887207031, 'encoder/train/loss': 0.9295709729194641}
epoch number:1 {'encoder/val/acc': 74.59663391113281, 'encoder/val/loss': 0.8388975262641907}
epoch number:2 {'encoder/train/acc': 76.68667602539062, 'encoder/train/loss': 0.795652449131012}
epoch number:2 {'encoder/val/acc': 76.3989028930664, 'encoder/val/loss': 0.8350419998168945}
                       overal progress   2/2 epochs ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:04                       
                       encoder/train/acc: 76.687 encoder/train/loss: 0.796  encoder/val/acc: 76.399 encoder/val/loss: 0.835     
                                                                                                                                
[12:56:16] INFO     bounding the number of neighbors per node...done in 10.34 s                                   gap_ndp.py:110
           INFO     computing aggregations...done in 0.00 s                                                       gap_inf.py:149
           INFO     training classifier                                                                               base.py:86
2
341
epoch number:1 {'train/acc': 88.02169799804688, 'train/loss': 0.4871339201927185}
epoch number:1 {'val/acc': 91.45211029052734, 'val/loss': 0.29841750860214233}
epoch number:2 {'train/acc': 91.78224182128906, 'train/loss': 0.2710064649581909}
epoch number:2 {'val/acc': 91.72674560546875, 'val/loss': 0.2772802710533142}
                       overal progress   2/2 epochs ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:04                       
                       train/acc: 91.782 train/loss: 0.271  val/acc: 91.727 val/loss: 0.277                                     
                                                                                                                                
[12:56:20] INFO                run 1                                                                                 train.py:66
                     ──────────────────────────                                                                                 
                      metric     last    mean                                                                                   
                     ──────────────────────────                                                                                 
                      test/acc   91.78   91.78                                                                                  
                     ──────────────────────────                                                                                 


[12:56:21] INFO     Total running time: 33.69 seconds.                                                              train.py:117
           INFO     Max GPU memory used = 1.74 GB                                                                   train.py:126
                                                                                                                                
[12:56:24] INFO     importing modules...done in 2.44 s                                                               train.py:16

           INFO                          program arguments                                                          utils.py:156
                     ─────────────────────────────────────────────────────────                                                  
                      method:          gap-ndp     encoder_epochs:   3                                                          
                      dataset:         reddit      epochs:           3                                                          
                      data_dir:        ./datasets  optimizer:        adam                                                       
                      delta:           auto        learning_rate:    0.01                                                       
                      max_degree:      100         weight_decay:     0.0                                                        
                      max_grad_norm:   1.0         full_batch_eval:  True                                                       
                      batch_size:      256         device:           cuda                                                       
                      hops:            2           val_interval:     1                                                          
                      hidden_dim:      16          seed:             12345                                                      
                      encoder_layers:  2           repeats:          1                                                          
                      base_layers:     1           debug:            False                                                      
                      head_layers:     1           logger:           csv                                                        
                      combine:         cat         project:          GAP                                                        
                      activation:      selu        output_dir:       ./output                                                   
                      dropout:         0.0         epsilon:          8.0                                                        
                     ─────────────────────────────────────────────────────────                                                  

[12:56:35] INFO                            dataset: reddit                                                          loader.py:76
                     ────────────────────────────────────────────────────────────                                               
                      nodes:     116,713     mean degree:         396.13                                                        
                      edges:     46,233,380  median degree:       209.0                                                         
                      features:  602         train/val/test (%):  75.0/10.0/15.0                                                
                      classes:   8           baseline acc (%):    24.35                                                         
                     ────────────────────────────────────────────────────────────                                               

           INFO     loading dataset...done in 10.72 s                                                                train.py:34
           INFO     delta = 1e-05                                                                                  gap_ndp.py:85
eps1 8.0
eps3 8.0
eps5 8.0
[12:56:36] INFO     noise scale: 0.9063                                                                            gap_ndp.py:90
                                                                                                                                
n 0.9063437993602609
           INFO     calibrating noise to privacy budget...done in 1.20 s                                           gap_ndp.py:92
[12:56:37] INFO     pretraining encoder                                                                           gap_inf.py:121
3
341
epoch number:1 {'encoder/train/acc': 70.4142837524414, 'encoder/train/loss': 0.9298067688941956}
epoch number:1 {'encoder/val/acc': 74.58805084228516, 'encoder/val/loss': 0.8388569951057434}
epoch number:2 {'encoder/train/acc': 76.67566680908203, 'encoder/train/loss': 0.7957932949066162}
epoch number:2 {'encoder/val/acc': 76.40747833251953, 'encoder/val/loss': 0.8351548314094543}
epoch number:3 {'encoder/train/acc': 77.75076293945312, 'encoder/train/loss': 0.7907548546791077}
epoch number:3 {'encoder/val/acc': 77.49742126464844, 'encoder/val/loss': 0.8140794634819031}
                       overal progress   3/3 epochs ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:07                       
                       encoder/train/acc: 77.751 encoder/train/loss: 0.791  encoder/val/acc: 77.497 encoder/val/loss: 0.814     
                                                                                                                                
[12:56:59] INFO     bounding the number of neighbors per node...done in 14.46 s                                   gap_ndp.py:110
           INFO     computing aggregations...done in 0.00 s                                                       gap_inf.py:149
           INFO     training classifier                                                                               base.py:86
3
341
epoch number:1 {'train/acc': 86.92549133300781, 'train/loss': 0.5009678602218628}
epoch number:1 {'val/acc': 91.18606567382812, 'val/loss': 0.29929861426353455}
epoch number:2 {'train/acc': 91.6820068359375, 'train/loss': 0.27575013041496277}
epoch number:2 {'val/acc': 91.7095718383789, 'val/loss': 0.2764175236225128}
epoch number:3 {'train/acc': 91.70364379882812, 'train/loss': 0.26830434799194336}
epoch number:3 {'val/acc': 91.78682708740234, 'val/loss': 0.27142059803009033}
                       overal progress   3/3 epochs ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:08                       
                       train/acc: 91.704 train/loss: 0.268  val/acc: 91.787 val/loss: 0.271                                     
                                                                                                                                
[12:57:07] INFO                run 1                                                                                 train.py:66
                     ──────────────────────────                                                                                 
                      metric     last    mean                                                                                   
                     ──────────────────────────                                                                                 
                      test/acc   91.90   91.90                                                                                  
                     ──────────────────────────                                                                                 


[12:57:08] INFO     Total running time: 43.70 seconds.                                                              train.py:117
           INFO     Max GPU memory used = 1.74 GB                                                                   train.py:126
                                                                                                                                
[12:57:11] INFO     importing modules...done in 2.46 s                                                               train.py:16

           INFO                          program arguments                                                          utils.py:156
                     ─────────────────────────────────────────────────────────                                                  
                      method:          gap-ndp     encoder_epochs:   4                                                          
                      dataset:         reddit      epochs:           4                                                          
                      data_dir:        ./datasets  optimizer:        adam                                                       
                      delta:           auto        learning_rate:    0.01                                                       
                      max_degree:      100         weight_decay:     0.0                                                        
                      max_grad_norm:   1.0         full_batch_eval:  True                                                       
                      batch_size:      256         device:           cuda                                                       
                      hops:            2           val_interval:     1                                                          
                      hidden_dim:      16          seed:             12345                                                      
                      encoder_layers:  2           repeats:          1                                                          
                      base_layers:     1           debug:            False                                                      
                      head_layers:     1           logger:           csv                                                        
                      combine:         cat         project:          GAP                                                        
                      activation:      selu        output_dir:       ./output                                                   
                      dropout:         0.0         epsilon:          8.0                                                        
                     ─────────────────────────────────────────────────────────                                                  

[12:57:22] INFO                            dataset: reddit                                                          loader.py:76
                     ────────────────────────────────────────────────────────────                                               
                      nodes:     116,713     mean degree:         396.13                                                        
                      edges:     46,233,380  median degree:       209.0                                                         
                      features:  602         train/val/test (%):  75.0/10.0/15.0                                                
                      classes:   8           baseline acc (%):    24.35                                                         
                     ────────────────────────────────────────────────────────────                                               

           INFO     loading dataset...done in 10.75 s                                                                train.py:34
           INFO     delta = 1e-05                                                                                  gap_ndp.py:85
eps1 8.0
eps3 8.0
eps5 8.0
[12:57:23] INFO     noise scale: 0.9078                                                                       gap_ndp.py:90
                                                                                                                           
n 0.9078481630379694
           INFO     calibrating noise to privacy budget...done in 1.24 s                                      gap_ndp.py:92
[12:57:24] INFO     pretraining encoder                                                            gap_inf.py:121
4
341
epoch number:1 {'encoder/train/acc': 70.39419555664062, 'encoder/train/loss': 0.9300013184547424}
epoch number:1 {'encoder/val/acc': 74.5794677734375, 'encoder/val/loss': 0.839002788066864}
epoch number:2 {'encoder/train/acc': 76.6761703491211, 'encoder/train/loss': 0.7958917021751404}
epoch number:2 {'encoder/val/acc': 76.42464447021484, 'encoder/val/loss': 0.8350866436958313}
epoch number:3 {'encoder/train/acc': 77.76358795166016, 'encoder/train/loss': 0.7908201217651367}
epoch number:3 {'encoder/val/acc': 77.54033660888672, 'encoder/val/loss': 0.8142032623291016}
epoch number:4 {'encoder/train/acc': 78.07597351074219, 'encoder/train/loss': 0.7878363132476807}
epoch number:4 {'encoder/val/acc': 77.43734741210938, 'encoder/val/loss': 0.8117735981941223}
                       overal progress   4/4 epochs ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:09        
                       encoder/train/acc: 78.076 encoder/train/loss: 0.788  encoder/val/acc: 77.437              
                       encoder/val/loss: 0.812                                                                   
                                                                                                                 
[12:57:44] INFO     bounding the number of neighbors per node...done in 10.12 s                    gap_ndp.py:110
           INFO     computing aggregations...done in 0.00 s                                        gap_inf.py:149
           INFO     training classifier                                                                base.py:86
4
341
epoch number:1 {'train/acc': 86.24766540527344, 'train/loss': 0.5085014700889587}
epoch number:1 {'val/acc': 91.07449340820312, 'val/loss': 0.3029208779335022}
epoch number:2 {'train/acc': 91.45742797851562, 'train/loss': 0.27825161814689636}
epoch number:2 {'val/acc': 91.34912109375, 'val/loss': 0.27695879340171814}
epoch number:3 {'train/acc': 91.88990783691406, 'train/loss': 0.2635354995727539}
epoch number:3 {'val/acc': 91.6237564086914, 'val/loss': 0.2774380147457123}
epoch number:4 {'train/acc': 92.01065063476562, 'train/loss': 0.2617337107658386}
epoch number:4 {'val/acc': 91.5979995727539, 'val/loss': 0.27463799715042114}
                       overal progress   4/4 epochs ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:09        
                       train/acc: 92.011 train/loss: 0.262  val/acc: 91.598 val/loss: 0.275                      
                                                                                                                 
[12:57:54] INFO                run 1                                                                  train.py:66
                     ──────────────────────────                                                                  
                      metric     last    mean                                                                    
                     ──────────────────────────                                                                  
                      test/acc   91.79   91.79                                                                   
                     ──────────────────────────                                                                  


           INFO     Total running time: 43.37 seconds.                                               train.py:117
           INFO     Max GPU memory used = 1.74 GB                                                    train.py:126
                                                                                                                 
[12:57:57] INFO     importing modules...done in 2.44 s                                                train.py:16

           INFO                          program arguments                                           utils.py:156
                     ─────────────────────────────────────────────────────────                                   
                      method:          gap-ndp     encoder_epochs:   5                                           
                      dataset:         reddit      epochs:           5                                           
                      data_dir:        ./datasets  optimizer:        adam                                        
                      delta:           auto        learning_rate:    0.01                                        
                      max_degree:      100         weight_decay:     0.0                                         
                      max_grad_norm:   1.0         full_batch_eval:  True                                        
                      batch_size:      256         device:           cuda                                        
                      hops:            2           val_interval:     1                                           
                      hidden_dim:      16          seed:             12345                                       
                      encoder_layers:  2           repeats:          1                                           
                      base_layers:     1           debug:            False                                       
                      head_layers:     1           logger:           csv                                         
                      combine:         cat         project:          GAP                                         
                      activation:      selu        output_dir:       ./output                                    
                      dropout:         0.0         epsilon:          8.0                                         
                     ─────────────────────────────────────────────────────────                                   

[12:58:08] INFO                            dataset: reddit                                           loader.py:76
                     ────────────────────────────────────────────────────────────                                
                      nodes:     116,713     mean degree:         396.13                                         
                      edges:     46,233,380  median degree:       209.0                                          
                      features:  602         train/val/test (%):  75.0/10.0/15.0                                 
                      classes:   8           baseline acc (%):    24.35                                          
                     ────────────────────────────────────────────────────────────                                

           INFO     loading dataset...done in 10.71 s                                                 train.py:34
           INFO     delta = 1e-05                                                                   gap_ndp.py:85
eps1 8.0
eps3 8.0
eps5 8.0
[12:58:09] INFO     noise scale: 0.9093                                                             gap_ndp.py:90
                                                                                                                 
n 0.9093439707801317
           INFO     calibrating noise to privacy budget...done in 1.32 s                            gap_ndp.py:92
[12:58:11] INFO     pretraining encoder                                                            gap_inf.py:121
5
341
epoch number:1 {'encoder/train/acc': 70.38902282714844, 'encoder/train/loss': 0.9302508234977722}
epoch number:1 {'encoder/val/acc': 74.57088470458984, 'encoder/val/loss': 0.8392142653465271}
epoch number:2 {'encoder/train/acc': 76.64634704589844, 'encoder/train/loss': 0.7961295247077942}
epoch number:2 {'encoder/val/acc': 76.44181060791016, 'encoder/val/loss': 0.8352851271629333}
epoch number:3 {'encoder/train/acc': 77.75263977050781, 'encoder/train/loss': 0.7910800576210022}
epoch number:3 {'encoder/val/acc': 77.5574951171875, 'encoder/val/loss': 0.8142789006233215}
epoch number:4 {'encoder/train/acc': 78.06450653076172, 'encoder/train/loss': 0.7880627512931824}
epoch number:4 {'encoder/val/acc': 77.42876434326172, 'encoder/val/loss': 0.8118427395820618}
epoch number:5 {'encoder/train/acc': 78.80813598632812, 'encoder/train/loss': 0.7552554607391357}
epoch number:5 {'encoder/val/acc': 78.05526733398438, 'encoder/val/loss': 0.7942872047424316}
                       overal progress   5/5 epochs ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:12        
                       encoder/train/acc: 78.808 encoder/train/loss: 0.755  encoder/val/acc: 78.055              
                       encoder/val/loss: 0.794                                                                   
                                                                                                                 
[12:58:39] INFO     bounding the number of neighbors per node...done in 15.32 s                    gap_ndp.py:110
           INFO     computing aggregations...done in 0.00 s                                        gap_inf.py:149
           INFO     training classifier                                                                base.py:86
5
341
epoch number:1 {'train/acc': 88.58158111572266, 'train/loss': 0.4870460033416748}
epoch number:1 {'val/acc': 91.55509185791016, 'val/loss': 0.29254958033561707}
epoch number:2 {'train/acc': 92.16232299804688, 'train/loss': 0.2626338303089142}
epoch number:2 {'val/acc': 91.89838409423828, 'val/loss': 0.27215445041656494}
epoch number:3 {'train/acc': 92.30989074707031, 'train/loss': 0.2523875832557678}
epoch number:3 {'val/acc': 91.94988250732422, 'val/loss': 0.2704310417175293}
epoch number:4 {'train/acc': 92.36588287353516, 'train/loss': 0.2516840994358063}
epoch number:4 {'val/acc': 92.09577178955078, 'val/loss': 0.26451724767684937}
epoch number:5 {'train/acc': 92.57096862792969, 'train/loss': 0.24594788253307343}
epoch number:5 {'val/acc': 92.1301040649414, 'val/loss': 0.2691868841648102}
                       overal progress   5/5 epochs ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:12        
                       train/acc: 92.571 train/loss: 0.246  val/acc: 92.130 val/loss: 0.269                      
                                                                                                                 
[12:58:52] INFO                run 1                                                                  train.py:66
                     ──────────────────────────                                                                  
                      metric     last    mean                                                                    
                     ──────────────────────────                                                                  
                      test/acc   92.30   92.30                                                                   
                     ──────────────────────────                                                                  


           INFO     Total running time: 54.59 seconds.                                               train.py:117
           INFO     Max GPU memory used = 1.74 GB                                                    train.py:126
                                                                                                                 
[12:58:55] INFO     importing modules...done in 2.41 s                                                train.py:16

           INFO                          program arguments                                           utils.py:156
                     ─────────────────────────────────────────────────────────                                   
                      method:          gap-ndp     encoder_epochs:   6                                           
                      dataset:         reddit      epochs:           6                                           
                      data_dir:        ./datasets  optimizer:        adam                                        
                      delta:           auto        learning_rate:    0.01                                        
                      max_degree:      100         weight_decay:     0.0                                         
                      max_grad_norm:   1.0         full_batch_eval:  True                                        
                      batch_size:      256         device:           cuda                                        
                      hops:            2           val_interval:     1                                           
                      hidden_dim:      16          seed:             12345                                       
                      encoder_layers:  2           repeats:          1                                           
                      base_layers:     1           debug:            False                                       
                      head_layers:     1           logger:           csv                                         
                      combine:         cat         project:          GAP                                         
                      activation:      selu        output_dir:       ./output                                    
                      dropout:         0.0         epsilon:          8.0                                         
                     ─────────────────────────────────────────────────────────                                   

[12:59:06] INFO                            dataset: reddit                                           loader.py:76
                     ────────────────────────────────────────────────────────────                                
                      nodes:     116,713     mean degree:         396.13                                         
                      edges:     46,233,380  median degree:       209.0                                          
                      features:  602         train/val/test (%):  75.0/10.0/15.0                                 
                      classes:   8           baseline acc (%):    24.35                                          
                     ────────────────────────────────────────────────────────────                                

           INFO     loading dataset...done in 10.73 s                                                 train.py:34
           INFO     delta = 1e-05                                                                   gap_ndp.py:85
eps1 8.0
eps3 8.0
eps5 8.0
[12:59:07] INFO     noise scale: 0.9108                                                             gap_ndp.py:90
                                                                                                                 
n 0.9108305869701074
           INFO     calibrating noise to privacy budget...done in 1.18 s                            gap_ndp.py:92
[12:59:09] INFO     pretraining encoder                                                            gap_inf.py:121
6
341
epoch number:1 {'encoder/train/acc': 70.38029479980469, 'encoder/train/loss': 0.9305246472358704}
epoch number:1 {'encoder/val/acc': 74.53656005859375, 'encoder/val/loss': 0.8395557999610901}
epoch number:2 {'encoder/train/acc': 76.6394271850586, 'encoder/train/loss': 0.7963945865631104}
epoch number:2 {'encoder/val/acc': 76.44181060791016, 'encoder/val/loss': 0.8354873657226562}
epoch number:3 {'encoder/train/acc': 77.7529525756836, 'encoder/train/loss': 0.7913342714309692}
epoch number:3 {'encoder/val/acc': 77.53175354003906, 'encoder/val/loss': 0.8144531846046448}
epoch number:4 {'encoder/train/acc': 78.06585693359375, 'encoder/train/loss': 0.7882463932037354}
epoch number:4 {'encoder/val/acc': 77.40302276611328, 'encoder/val/loss': 0.8121448159217834}
epoch number:5 {'encoder/train/acc': 78.80528259277344, 'encoder/train/loss': 0.7554594874382019}
epoch number:5 {'encoder/val/acc': 78.05526733398438, 'encoder/val/loss': 0.794546902179718}
epoch number:6 {'encoder/train/acc': 79.22705078125, 'encoder/train/loss': 0.7335496544837952}
epoch number:6 {'encoder/val/acc': 77.71198272705078, 'encoder/val/loss': 0.7945523262023926}
                       overal progress   6/6 epochs ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:13        
                       encoder/train/acc: 79.227 encoder/train/loss: 0.734  encoder/val/acc: 77.712              
                       encoder/val/loss: 0.795                                                                   
                                                                                                                 
[12:59:33] INFO     bounding the number of neighbors per node...done in 10.26 s                    gap_ndp.py:110
           INFO     computing aggregations...done in 0.00 s                                        gap_inf.py:149
           INFO     training classifier                                                                base.py:86
6
341
epoch number:1 {'train/acc': 87.21411895751953, 'train/loss': 0.48797607421875}
epoch number:1 {'val/acc': 91.4950180053711, 'val/loss': 0.28603610396385193}
epoch number:2 {'train/acc': 92.14470672607422, 'train/loss': 0.25998035073280334}
epoch number:2 {'val/acc': 92.06143951416016, 'val/loss': 0.2642934024333954}
epoch number:3 {'train/acc': 92.17137145996094, 'train/loss': 0.2535953223705292}
epoch number:3 {'val/acc': 91.97562408447266, 'val/loss': 0.2660030722618103}
epoch number:4 {'train/acc': 92.31201934814453, 'train/loss': 0.25252431631088257}
epoch number:4 {'val/acc': 92.18160247802734, 'val/loss': 0.26084694266319275}
epoch number:5 {'train/acc': 92.3431625366211, 'train/loss': 0.24978703260421753}
epoch number:5 {'val/acc': 92.04428100585938, 'val/loss': 0.2645144462585449}
epoch number:6 {'train/acc': 92.26002502441406, 'train/loss': 0.25495684146881104}
epoch number:6 {'val/acc': 92.09577178955078, 'val/loss': 0.26459914445877075}
                       overal progress   6/6 epochs ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:13        
                       train/acc: 92.260 train/loss: 0.255  val/acc: 92.096 val/loss: 0.265                      
                                                                                                                 
[12:59:46] INFO                run 1                                                                  train.py:66
                     ──────────────────────────                                                                  
                      metric     last    mean                                                                    
                     ──────────────────────────                                                                  
                      test/acc   92.17   92.17                                                                   
                     ──────────────────────────                                                                  


[12:59:47] INFO     Total running time: 51.33 seconds.                                               train.py:117
           INFO     Max GPU memory used = 1.74 GB                                                    train.py:126
                                                                                                                 
[12:59:50] INFO     importing modules...done in 2.44 s                                                train.py:16

           INFO                          program arguments                                           utils.py:156
                     ─────────────────────────────────────────────────────────                                   
                      method:          gap-ndp     encoder_epochs:   7                                           
                      dataset:         reddit      epochs:           7                                           
                      data_dir:        ./datasets  optimizer:        adam                                        
                      delta:           auto        learning_rate:    0.01                                        
                      max_degree:      100         weight_decay:     0.0                                         
                      max_grad_norm:   1.0         full_batch_eval:  True                                        
                      batch_size:      256         device:           cuda                                        
                      hops:            2           val_interval:     1                                           
                      hidden_dim:      16          seed:             12345                                       
                      encoder_layers:  2           repeats:          1                                           
                      base_layers:     1           debug:            False                                       
                      head_layers:     1           logger:           csv                                         
                      combine:         cat         project:          GAP                                         
                      activation:      selu        output_dir:       ./output                                    
                      dropout:         0.0         epsilon:          8.0                                         
                     ─────────────────────────────────────────────────────────                                   

[13:00:00] INFO                            dataset: reddit                                           loader.py:76
                     ────────────────────────────────────────────────────────────                                
                      nodes:     116,713     mean degree:         396.13                                         
                      edges:     46,233,380  median degree:       209.0                                          
                      features:  602         train/val/test (%):  75.0/10.0/15.0                                 
                      classes:   8           baseline acc (%):    24.35                                          
                     ────────────────────────────────────────────────────────────                                

           INFO     loading dataset...done in 10.66 s                                                 train.py:34
           INFO     delta = 1e-05                                                                   gap_ndp.py:85
eps1 8.0
eps3 8.0
eps5 8.0
[13:00:02] INFO     noise scale: 0.9123                                                             gap_ndp.py:90
                                                                                                                 
n 0.9123076751206137
           INFO     calibrating noise to privacy budget...done in 1.37 s                            gap_ndp.py:92
[13:00:04] INFO     pretraining encoder                                                            gap_inf.py:121
7
341
epoch number:1 {'encoder/train/acc': 70.35393524169922, 'encoder/train/loss': 0.9308475852012634}
epoch number:1 {'encoder/val/acc': 74.56230163574219, 'encoder/val/loss': 0.8397079110145569}
epoch number:2 {'encoder/train/acc': 76.62625122070312, 'encoder/train/loss': 0.7965572476387024}
epoch number:2 {'encoder/val/acc': 76.39031982421875, 'encoder/val/loss': 0.8353266716003418}
epoch number:3 {'encoder/train/acc': 77.74874877929688, 'encoder/train/loss': 0.7914008498191833}
epoch number:3 {'encoder/val/acc': 77.51458740234375, 'encoder/val/loss': 0.814555823802948}
epoch number:4 {'encoder/train/acc': 78.06021118164062, 'encoder/train/loss': 0.7884172201156616}
epoch number:4 {'encoder/val/acc': 77.4201889038086, 'encoder/val/loss': 0.8121731281280518}
epoch number:5 {'encoder/train/acc': 78.79693603515625, 'encoder/train/loss': 0.7556261420249939}
epoch number:5 {'encoder/val/acc': 78.06385040283203, 'encoder/val/loss': 0.794623613357544}
epoch number:6 {'encoder/train/acc': 79.21340942382812, 'encoder/train/loss': 0.7337075471878052}
epoch number:6 {'encoder/val/acc': 77.73772430419922, 'encoder/val/loss': 0.7946850657463074}
epoch number:7 {'encoder/train/acc': 79.37764739990234, 'encoder/train/loss': 0.7300863862037659}
epoch number:7 {'encoder/val/acc': 77.866455078125, 'encoder/val/loss': 0.7909747958183289}
                       overal progress   7/7 epochs ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:16        
                       encoder/train/acc: 79.378 encoder/train/loss: 0.730  encoder/val/acc: 77.866              
                       encoder/val/loss: 0.791                                                                   
                                                                                                                 
[13:00:30] INFO     bounding the number of neighbors per node...done in 9.82 s                     gap_ndp.py:110
           INFO     computing aggregations...done in 0.00 s                                        gap_inf.py:149
           INFO     training classifier                                                                base.py:86
7
341
epoch number:1 {'train/acc': 86.88131713867188, 'train/loss': 0.48800361156463623}
epoch number:1 {'val/acc': 91.7095718383789, 'val/loss': 0.284569650888443}
epoch number:2 {'train/acc': 92.08283233642578, 'train/loss': 0.2579447329044342}
epoch number:2 {'val/acc': 91.97562408447266, 'val/loss': 0.2642938792705536}
epoch number:3 {'train/acc': 92.24606323242188, 'train/loss': 0.25193116068840027}
epoch number:3 {'val/acc': 91.83831024169922, 'val/loss': 0.2695625424385071}
epoch number:4 {'train/acc': 92.40766906738281, 'train/loss': 0.2467392235994339}
epoch number:4 {'val/acc': 91.98421478271484, 'val/loss': 0.2673451006412506}
epoch number:5 {'train/acc': 92.3739242553711, 'train/loss': 0.2482711672782898}
epoch number:5 {'val/acc': 92.04428100585938, 'val/loss': 0.262940913438797}
epoch number:6 {'train/acc': 92.38185119628906, 'train/loss': 0.24653483927249908}
epoch number:6 {'val/acc': 91.85546875, 'val/loss': 0.2703547477722168}
epoch number:7 {'train/acc': 92.43354034423828, 'train/loss': 0.24875694513320923}
epoch number:7 {'val/acc': 92.08719635009766, 'val/loss': 0.26593005657196045}
                       overal progress   7/7 epochs ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:17        
                       train/acc: 92.434 train/loss: 0.249  val/acc: 92.087 val/loss: 0.266                      
                                                                                                                 
[13:00:47] INFO                run 1                                                                  train.py:66
                     ──────────────────────────                                                                  
                      metric     last    mean                                                                    
                     ──────────────────────────                                                                  
                      test/acc   92.07   92.07                                                                   
                     ──────────────────────────                                                                  


           INFO     Total running time: 57.59 seconds.                                               train.py:117
           INFO     Max GPU memory used = 1.74 GB                                                    train.py:126
                                                                                                                 
[13:00:51] INFO     importing modules...done in 2.42 s                                                train.py:16

           INFO                          program arguments                                           utils.py:156
                     ─────────────────────────────────────────────────────────                                   
                      method:          gap-ndp     encoder_epochs:   8                                           
                      dataset:         reddit      epochs:           8                                           
                      data_dir:        ./datasets  optimizer:        adam                                        
                      delta:           auto        learning_rate:    0.01                                        
                      max_degree:      100         weight_decay:     0.0                                         
                      max_grad_norm:   1.0         full_batch_eval:  True                                        
                      batch_size:      256         device:           cuda                                        
                      hops:            2           val_interval:     1                                           
                      hidden_dim:      16          seed:             12345                                       
                      encoder_layers:  2           repeats:          1                                           
                      base_layers:     1           debug:            False                                       
                      head_layers:     1           logger:           csv                                         
                      combine:         cat         project:          GAP                                         
                      activation:      selu        output_dir:       ./output                                    
                      dropout:         0.0         epsilon:          8.0                                         
                     ─────────────────────────────────────────────────────────                                   

[13:01:01] INFO                            dataset: reddit                                           loader.py:76
                     ────────────────────────────────────────────────────────────                                
                      nodes:     116,713     mean degree:         396.13                                         
                      edges:     46,233,380  median degree:       209.0                                          
                      features:  602         train/val/test (%):  75.0/10.0/15.0                                 
                      classes:   8           baseline acc (%):    24.35                                          
                     ────────────────────────────────────────────────────────────                                

           INFO     loading dataset...done in 10.72 s                                                 train.py:34
           INFO     delta = 1e-05                                                                   gap_ndp.py:85
eps1 8.0
eps3 8.0
eps5 8.0
[13:01:03] INFO     noise scale: 0.9138                                                             gap_ndp.py:90
                                                                                                                 
n 0.9137752846269579
           INFO     calibrating noise to privacy budget...done in 1.22 s                            gap_ndp.py:92
[13:01:04] INFO     pretraining encoder                                                            gap_inf.py:121
8
341
epoch number:1 {'encoder/train/acc': 70.3455581665039, 'encoder/train/loss': 0.9311100840568542}
epoch number:1 {'encoder/val/acc': 74.5279769897461, 'encoder/val/loss': 0.8400666117668152}
epoch number:2 {'encoder/train/acc': 76.61933135986328, 'encoder/train/loss': 0.796788215637207}
epoch number:2 {'encoder/val/acc': 76.35598754882812, 'encoder/val/loss': 0.8354618549346924}
epoch number:3 {'encoder/train/acc': 77.74026489257812, 'encoder/train/loss': 0.7916250824928284}
epoch number:3 {'encoder/val/acc': 77.5060043334961, 'encoder/val/loss': 0.8147372603416443}
epoch number:4 {'encoder/train/acc': 78.04865264892578, 'encoder/train/loss': 0.7886509895324707}
epoch number:4 {'encoder/val/acc': 77.4201889038086, 'encoder/val/loss': 0.8124625086784363}
epoch number:5 {'encoder/train/acc': 78.78082275390625, 'encoder/train/loss': 0.7557880878448486}
epoch number:5 {'encoder/val/acc': 78.08101654052734, 'encoder/val/loss': 0.7947530746459961}
epoch number:6 {'encoder/train/acc': 79.21459197998047, 'encoder/train/loss': 0.7338302135467529}
epoch number:6 {'encoder/val/acc': 77.71198272705078, 'encoder/val/loss': 0.7948203682899475}
epoch number:7 {'encoder/train/acc': 79.3646240234375, 'encoder/train/loss': 0.7302206158638}
epoch number:7 {'encoder/val/acc': 77.8321304321289, 'encoder/val/loss': 0.7911247611045837}
epoch number:8 {'encoder/train/acc': 79.30049896240234, 'encoder/train/loss': 0.7252927422523499}
epoch number:8 {'encoder/val/acc': 78.1410903930664, 'encoder/val/loss': 0.7630608677864075}
                       overal progress   8/8 epochs ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:18        
                       encoder/train/acc: 79.300 encoder/train/loss: 0.725  encoder/val/acc: 78.141              
                       encoder/val/loss: 0.763                                                                   
                                                                                                                 
[13:01:32] INFO     bounding the number of neighbors per node...done in 10.04 s                    gap_ndp.py:110
           INFO     computing aggregations...done in 0.00 s                                        gap_inf.py:149
           INFO     training classifier                                                                base.py:86
8
341
epoch number:1 {'train/acc': 87.5768051147461, 'train/loss': 0.4891504943370819}
epoch number:1 {'val/acc': 91.8211441040039, 'val/loss': 0.2763978838920593}
epoch number:2 {'train/acc': 92.15570068359375, 'train/loss': 0.2565746605396271}
epoch number:2 {'val/acc': 91.94988250732422, 'val/loss': 0.2632274329662323}
epoch number:3 {'train/acc': 92.25798034667969, 'train/loss': 0.2522141933441162}
epoch number:3 {'val/acc': 92.08719635009766, 'val/loss': 0.2557337284088135}
epoch number:4 {'train/acc': 92.45989227294922, 'train/loss': 0.24475166201591492}
epoch number:4 {'val/acc': 91.9155502319336, 'val/loss': 0.25939834117889404}
epoch number:5 {'train/acc': 92.37435150146484, 'train/loss': 0.24950863420963287}
epoch number:5 {'val/acc': 92.00995635986328, 'val/loss': 0.25756993889808655}
epoch number:6 {'train/acc': 92.41111755371094, 'train/loss': 0.24699430167675018}
epoch number:6 {'val/acc': 91.9327163696289, 'val/loss': 0.2572678327560425}
epoch number:7 {'train/acc': 92.36894989013672, 'train/loss': 0.2534804046154022}
epoch number:7 {'val/acc': 92.0185317993164, 'val/loss': 0.25670409202575684}
epoch number:8 {'train/acc': 92.4464111328125, 'train/loss': 0.2504599094390869}
epoch number:8 {'val/acc': 92.07861328125, 'val/loss': 0.2557219862937927}
                       overal progress   8/8 epochs ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:19        
                       train/acc: 92.446 train/loss: 0.250  val/acc: 92.079 val/loss: 0.256                      
                                                                                                                 
[13:01:52] INFO                run 1                                                                  train.py:66
                     ──────────────────────────                                                                  
                      metric     last    mean                                                                    
                     ──────────────────────────                                                                  
                      test/acc   92.25   92.25                                                                   
                     ──────────────────────────                                                                  


           INFO     Total running time: 61.70 seconds.                                               train.py:117
           INFO     Max GPU memory used = 1.74 GB                                                    train.py:126
                                                                                                                 
[13:01:55] INFO     importing modules...done in 2.42 s                                                train.py:16

           INFO                          program arguments                                           utils.py:156
                     ─────────────────────────────────────────────────────────                                   
                      method:          gap-ndp     encoder_epochs:   9                                           
                      dataset:         reddit      epochs:           9                                           
                      data_dir:        ./datasets  optimizer:        adam                                        
                      delta:           auto        learning_rate:    0.01                                        
                      max_degree:      100         weight_decay:     0.0                                         
                      max_grad_norm:   1.0         full_batch_eval:  True                                        
                      batch_size:      256         device:           cuda                                        
                      hops:            2           val_interval:     1                                           
                      hidden_dim:      16          seed:             12345                                       
                      encoder_layers:  2           repeats:          1                                           
                      base_layers:     1           debug:            False                                       
                      head_layers:     1           logger:           csv                                         
                      combine:         cat         project:          GAP                                         
                      activation:      selu        output_dir:       ./output                                    
                      dropout:         0.0         epsilon:          8.0                                         
                     ─────────────────────────────────────────────────────────                                   

[13:02:06] INFO                            dataset: reddit                                           loader.py:76
                     ────────────────────────────────────────────────────────────                                
                      nodes:     116,713     mean degree:         396.13                                         
                      edges:     46,233,380  median degree:       209.0                                          
                      features:  602         train/val/test (%):  75.0/10.0/15.0                                 
                      classes:   8           baseline acc (%):    24.35                                          
                     ────────────────────────────────────────────────────────────                                

           INFO     loading dataset...done in 10.69 s                                                 train.py:34
           INFO     delta = 1e-05                                                                   gap_ndp.py:85
eps1 8.0
eps3 8.0
eps5 8.0
[13:02:07] INFO     noise scale: 0.9152                                                             gap_ndp.py:90
                                                                                                                 
n 0.915234656753316
           INFO     calibrating noise to privacy budget...done in 1.24 s                            gap_ndp.py:92
[13:02:09] INFO     pretraining encoder                                                            gap_inf.py:121
9
341
epoch number:1 {'encoder/train/acc': 70.34246826171875, 'encoder/train/loss': 0.9313953518867493}
epoch number:1 {'encoder/val/acc': 74.56230163574219, 'encoder/val/loss': 0.8400701880455017}
epoch number:2 {'encoder/train/acc': 76.60425567626953, 'encoder/train/loss': 0.7970098257064819}
epoch number:2 {'encoder/val/acc': 76.3817367553711, 'encoder/val/loss': 0.8357579708099365}
epoch number:3 {'encoder/train/acc': 77.7256088256836, 'encoder/train/loss': 0.7917962074279785}
epoch number:3 {'encoder/val/acc': 77.54033660888672, 'encoder/val/loss': 0.8148205280303955}
epoch number:4 {'encoder/train/acc': 78.04292297363281, 'encoder/train/loss': 0.7888965010643005}
epoch number:4 {'encoder/val/acc': 77.41160583496094, 'encoder/val/loss': 0.8126769065856934}
epoch number:5 {'encoder/train/acc': 78.77557373046875, 'encoder/train/loss': 0.7561373114585876}
epoch number:5 {'encoder/val/acc': 78.04668426513672, 'encoder/val/loss': 0.7948920130729675}
epoch number:6 {'encoder/train/acc': 79.20230102539062, 'encoder/train/loss': 0.7340284585952759}
epoch number:6 {'encoder/val/acc': 77.68623352050781, 'encoder/val/loss': 0.7948956489562988}
epoch number:7 {'encoder/train/acc': 79.37053680419922, 'encoder/train/loss': 0.7304288148880005}
epoch number:7 {'encoder/val/acc': 77.88362121582031, 'encoder/val/loss': 0.7912629246711731}
epoch number:8 {'encoder/train/acc': 79.29548645019531, 'encoder/train/loss': 0.7254430651664734}
epoch number:8 {'encoder/val/acc': 78.1410903930664, 'encoder/val/loss': 0.7631681561470032}
epoch number:9 {'encoder/train/acc': 79.50482940673828, 'encoder/train/loss': 0.716916024684906}
epoch number:9 {'encoder/val/acc': 78.09817504882812, 'encoder/val/loss': 0.7656897902488708}
                       overal progress   9/9 epochs ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:22        
                       encoder/train/acc: 79.505 encoder/train/loss: 0.717  encoder/val/acc: 78.098              
                       encoder/val/loss: 0.766                                                                   
                                                                                                                 
[13:02:45] INFO     bounding the number of neighbors per node...done in 14.12 s                    gap_ndp.py:110
           INFO     computing aggregations...done in 0.00 s                                        gap_inf.py:149
           INFO     training classifier                                                                base.py:86
9
341
epoch number:1 {'train/acc': 88.25782012939453, 'train/loss': 0.48354366421699524}
epoch number:1 {'val/acc': 91.68383026123047, 'val/loss': 0.2816685140132904}
epoch number:2 {'train/acc': 92.1719741821289, 'train/loss': 0.2586328387260437}
epoch number:2 {'val/acc': 92.00995635986328, 'val/loss': 0.2642284631729126}
epoch number:3 {'train/acc': 92.24420166015625, 'train/loss': 0.25513505935668945}
epoch number:3 {'val/acc': 91.97562408447266, 'val/loss': 0.2592439353466034}
epoch number:4 {'train/acc': 92.38706970214844, 'train/loss': 0.24879945814609528}
epoch number:4 {'val/acc': 91.9327163696289, 'val/loss': 0.2614248991012573}
epoch number:5 {'train/acc': 92.2524185180664, 'train/loss': 0.2511324882507324}
epoch number:5 {'val/acc': 92.16443634033203, 'val/loss': 0.2622872591018677}
epoch number:6 {'train/acc': 92.41583251953125, 'train/loss': 0.2490541636943817}
epoch number:6 {'val/acc': 91.83831024169922, 'val/loss': 0.2689911425113678}
epoch number:7 {'train/acc': 92.34771728515625, 'train/loss': 0.2499251812696457}
epoch number:7 {'val/acc': 92.20735931396484, 'val/loss': 0.26448220014572144}
epoch number:8 {'train/acc': 92.44466400146484, 'train/loss': 0.2517489492893219}
epoch number:8 {'val/acc': 92.14727020263672, 'val/loss': 0.2626711428165436}
epoch number:9 {'train/acc': 92.461669921875, 'train/loss': 0.25170883536338806}
epoch number:9 {'val/acc': 92.08719635009766, 'val/loss': 0.2636404037475586}
                       overal progress   9/9 epochs ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:24        
                       train/acc: 92.462 train/loss: 0.252  val/acc: 92.087 val/loss: 0.264                      
                                                                                                                 
[13:03:10] INFO                run 1                                                                  train.py:66
                     ──────────────────────────                                                                  
                      metric     last    mean                                                                    
                     ──────────────────────────                                                                  
                      test/acc   92.07   92.07                                                                   
                     ──────────────────────────                                                                  


           INFO     Total running time: 74.27 seconds.                                               train.py:117
           INFO     Max GPU memory used = 1.74 GB                                                    train.py:126
                                                                                                                 
[13:03:13] INFO     importing modules...done in 2.43 s                                                train.py:16

           INFO                          program arguments                                           utils.py:156
                     ─────────────────────────────────────────────────────────                                   
                      method:          gap-ndp     encoder_epochs:   10                                          
                      dataset:         reddit      epochs:           10                                          
                      data_dir:        ./datasets  optimizer:        adam                                        
                      delta:           auto        learning_rate:    0.01                                        
                      max_degree:      100         weight_decay:     0.0                                         
                      max_grad_norm:   1.0         full_batch_eval:  True                                        
                      batch_size:      256         device:           cuda                                        
                      hops:            2           val_interval:     1                                           
                      hidden_dim:      16          seed:             12345                                       
                      encoder_layers:  2           repeats:          1                                           
                      base_layers:     1           debug:            False                                       
                      head_layers:     1           logger:           csv                                         
                      combine:         cat         project:          GAP                                         
                      activation:      selu        output_dir:       ./output                                    
                      dropout:         0.0         epsilon:          8.0                                         
                     ─────────────────────────────────────────────────────────                                   

[13:03:24] INFO                            dataset: reddit                                           loader.py:76
                     ────────────────────────────────────────────────────────────                                
                      nodes:     116,713     mean degree:         396.13                                         
                      edges:     46,233,380  median degree:       209.0                                          
                      features:  602         train/val/test (%):  75.0/10.0/15.0                                 
                      classes:   8           baseline acc (%):    24.35                                          
                     ────────────────────────────────────────────────────────────                                

           INFO     loading dataset...done in 10.81 s                                                 train.py:34
           INFO     delta = 1e-05                                                                   gap_ndp.py:85
eps1 8.0
eps3 8.0
eps5 8.0
[13:03:25] INFO     noise scale: 0.9167                                                             gap_ndp.py:90
                                                                                                                 
n 0.9166815810472246
           INFO     calibrating noise to privacy budget...done in 1.21 s                            gap_ndp.py:92
[13:03:27] INFO     pretraining encoder                                                            gap_inf.py:121
10
341
epoch number:1 {'encoder/train/acc': 70.33634185791016, 'encoder/train/loss': 0.9316158890724182}
epoch number:1 {'encoder/val/acc': 74.51939392089844, 'encoder/val/loss': 0.8403487205505371}
epoch number:2 {'encoder/train/acc': 76.59532928466797, 'encoder/train/loss': 0.7971578240394592}
epoch number:2 {'encoder/val/acc': 76.33882904052734, 'encoder/val/loss': 0.8356172442436218}
epoch number:3 {'encoder/train/acc': 77.71855926513672, 'encoder/train/loss': 0.791912853717804}
epoch number:3 {'encoder/val/acc': 77.5574951171875, 'encoder/val/loss': 0.8149906992912292}
epoch number:4 {'encoder/train/acc': 78.04058074951172, 'encoder/train/loss': 0.7890533208847046}
epoch number:4 {'encoder/val/acc': 77.39443969726562, 'encoder/val/loss': 0.8127703666687012}
epoch number:5 {'encoder/train/acc': 78.7683334350586, 'encoder/train/loss': 0.7562693357467651}
epoch number:5 {'encoder/val/acc': 78.04668426513672, 'encoder/val/loss': 0.7952343821525574}
epoch number:6 {'encoder/train/acc': 79.18636322021484, 'encoder/train/loss': 0.7342860698699951}
epoch number:6 {'encoder/val/acc': 77.69481658935547, 'encoder/val/loss': 0.7949320673942566}
epoch number:7 {'encoder/train/acc': 79.36265563964844, 'encoder/train/loss': 0.7306197881698608}
epoch number:7 {'encoder/val/acc': 77.88362121582031, 'encoder/val/loss': 0.7914836406707764}
epoch number:8 {'encoder/train/acc': 79.2821273803711, 'encoder/train/loss': 0.7256724834442139}
epoch number:8 {'encoder/val/acc': 78.13250732421875, 'encoder/val/loss': 0.7633177638053894}
epoch number:9 {'encoder/train/acc': 79.50553131103516, 'encoder/train/loss': 0.7171480655670166}
epoch number:9 {'encoder/val/acc': 78.07243347167969, 'encoder/val/loss': 0.7658539414405823}
epoch number:10 {'encoder/train/acc': 79.79487609863281, 'encoder/train/loss': 0.7127605676651001}
epoch number:10 {'encoder/val/acc': 78.2869873046875, 'encoder/val/loss': 0.7609415650367737}
                       overal progress  10/10 epochs ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:24       
                       encoder/train/acc: 79.795 encoder/train/loss: 0.713  encoder/val/acc: 78.287              
                       encoder/val/loss: 0.761                                                                   
                                                                                                                 
[13:04:01] INFO     bounding the number of neighbors per node...done in 10.09 s                    gap_ndp.py:110
           INFO     computing aggregations...done in 0.00 s                                        gap_inf.py:149
           INFO     training classifier                                                                base.py:86
10
341
epoch number:1 {'train/acc': 87.43877410888672, 'train/loss': 0.4766955077648163}
epoch number:1 {'val/acc': 91.48644256591797, 'val/loss': 0.27712059020996094}
epoch number:2 {'train/acc': 92.26657104492188, 'train/loss': 0.25459444522857666}
epoch number:2 {'val/acc': 91.8211441040039, 'val/loss': 0.2579415440559387}
epoch number:3 {'train/acc': 92.2398681640625, 'train/loss': 0.25487178564071655}
epoch number:3 {'val/acc': 91.94988250732422, 'val/loss': 0.2577412724494934}
epoch number:4 {'train/acc': 92.55250549316406, 'train/loss': 0.24334239959716797}
epoch number:4 {'val/acc': 92.07861328125, 'val/loss': 0.2593315839767456}
epoch number:5 {'train/acc': 92.586669921875, 'train/loss': 0.24176254868507385}
epoch number:5 {'val/acc': 92.08719635009766, 'val/loss': 0.2508401572704315}
epoch number:6 {'train/acc': 92.61119079589844, 'train/loss': 0.2453184425830841}
epoch number:6 {'val/acc': 92.04428100585938, 'val/loss': 0.2590770721435547}
epoch number:7 {'train/acc': 92.61772155761719, 'train/loss': 0.24963194131851196}
epoch number:7 {'val/acc': 92.07003021240234, 'val/loss': 0.2582455575466156}
epoch number:8 {'train/acc': 92.8604736328125, 'train/loss': 0.24265487492084503}
epoch number:8 {'val/acc': 92.1301040649414, 'val/loss': 0.2552490830421448}
epoch number:9 {'train/acc': 92.5692138671875, 'train/loss': 0.25359025597572327}
epoch number:9 {'val/acc': 92.190185546875, 'val/loss': 0.25853097438812256}
epoch number:10 {'train/acc': 92.70805358886719, 'train/loss': 0.24724097549915314}
epoch number:10 {'val/acc': 92.19876861572266, 'val/loss': 0.2584780752658844}
                       overal progress  10/10 epochs ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:25       
                       train/acc: 92.708 train/loss: 0.247  val/acc: 92.199 val/loss: 0.258                      
                                                                                                                 
[13:04:27] INFO                run 1                                                                  train.py:66
                     ──────────────────────────                                                                  
                      metric     last    mean                                                                    
                     ──────────────────────────                                                                  
                      test/acc   92.37   92.37                                                                   
                     ──────────────────────────                                                                  


           INFO     Total running time: 74.30 seconds.                                               train.py:117
           INFO     Max GPU memory used = 1.74 GB                                                    train.py:126
                                                                                                                 

                                                  